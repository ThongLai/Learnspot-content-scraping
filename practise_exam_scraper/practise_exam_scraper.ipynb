{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132c6fa0-694c-409b-8aed-6b0da3451e11",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- [ Required Packages](#RP)\n",
    "- [ Define Functions](#DF)\n",
    "  - [ Utility Functions](#UF)\n",
    "  - [ MathPix](#MP)\n",
    "  - [ OpenAI](#OA)\n",
    "- [ Execution ](#E)\n",
    "    - [ Read URLS from file ](#RUFF)\n",
    "    - [ Convert PDFs into LaTeX (MathPix APIs) ](#CPIL)\n",
    "    - [ Get LaTeX contents using `pdf_ids` (MathPix APIs) ](#GLCUP)\n",
    "    - [ Injecting into LLM (OpenAI APIs) ](#IJIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771cccc6-7c7b-43d6-9f31-c91b19b30a2d",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Ensure that all necessary environment variables for the MathPix API and OpenAI API are set before running the project. Review the output files for accuracy and completeness after processing.\n",
    "\n",
    "Documentation for this notebook can be found here: [Practise Exam Scraper Notebook Documentation](https://github.com/ThongLai/Learnspot-content-scraping/blob/main/practise_exam_scraper/practise_exam_scraper.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33981e84",
   "metadata": {
    "height": 30
   },
   "source": [
    "<a name=\"RP\"></a>\n",
    "# Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f0a724",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# Run the following commend if there is a missing package:\n",
    "# %pip install msgraph-sdk ipykernel openai tiktoken pandas xlsxwriter requests openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1124b54e",
   "metadata": {
    "height": 218
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xlsxwriter\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a6f7cd-d2b9-4104-be03-75be0893df2b",
   "metadata": {},
   "source": [
    "<a name=\"DF\"></a>\n",
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e16cc2-e4a8-43f8-acd4-19cc80de39ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"UF\"></a>\n",
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dea77c0-71ad-4e01-bd2f-602366e0f6e9",
   "metadata": {
    "height": 1282
   },
   "outputs": [],
   "source": [
    "def get_pdf_embed_links(url):\n",
    "    if \"https://pmt\" not in url:\n",
    "        # Extract the 'pdf' parameter from the query string\n",
    "        parsed_url = urllib.parse.urlparse(url)\n",
    "        pdf_url = urllib.parse.parse_qs(parsed_url.query)['pdf'][0]\n",
    "        \n",
    "        # Decode the URL\n",
    "        decoded_url = urllib.parse.unquote(pdf_url).replace(' ', '%20')\n",
    "        return decoded_url\n",
    "    else:\n",
    "        return url.replace(' ', '%20')\n",
    "\n",
    "def get_urls_from_file(filename = 'input_urls.txt'):\n",
    "    urls = []\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    year_group = lines[0].strip()\n",
    "    subject = lines[1].strip()\n",
    "    sub_topic = lines[2].strip()\n",
    "    \n",
    "    url_group = []\n",
    "    for line in lines[3:]:\n",
    "        url_group = line.strip().split(' https://')\n",
    "        url_group[0] = get_pdf_embed_links(url_group[0])\n",
    "        url_group[1] = get_pdf_embed_links(f'{'https://'}{url_group[1]}')\n",
    "    \n",
    "        if len(url_group) == 2:\n",
    "            urls.append(tuple(url_group))\n",
    "        else:\n",
    "            print(f'Missing 1 pair: {url_group}')\n",
    "\n",
    "    if len(lines) == len(urls)+3:\n",
    "        print(f\"[{len(urls)}] Read urls\")\n",
    "    else:\n",
    "        print(f\"[{len(urls)}] Failed to read urls\")\n",
    "    \n",
    "    return year_group, subject, sub_topic, urls\n",
    "\n",
    "def fix_latex_delimiters(latex_string):\n",
    "    if not isinstance(latex_string, str):\n",
    "        return latex_string\n",
    "        \n",
    "    # Count the number of double dollar signs\n",
    "    double_dollar_count = latex_string.count('$$')\n",
    "    \n",
    "    # Check if the count of double dollar signs is odd\n",
    "    if double_dollar_count % 2 != 0:\n",
    "        latex_string += ' $$'\n",
    "        \n",
    "    # Count the number of single dollar signs\n",
    "    single_dollar_count = latex_string.count('$')\n",
    "    \n",
    "    # Check if the count of single dollar signs is odd\n",
    "    if single_dollar_count % 2 != 0:\n",
    "        latex_string += ' $'\n",
    "    \n",
    "    return latex_string\n",
    "\n",
    "# Save to excel file with Data Validation\n",
    "def save_excel(output_file, practise_data, output_folder='.output'):\n",
    "    if not practise_data:\n",
    "        return\n",
    "    \n",
    "    df = pd.DataFrame(practise_data).rename(columns={'Question':'Question_Title'})\n",
    "    df.insert(1, 'Year Group', year_group)\n",
    "    df.insert(2, 'Subject', subject)\n",
    "    df.insert(3, 'Sub-Topic', sub_topic)\n",
    "    df.insert(6, 'Type of question', \"Practise Exam\")\n",
    "    df.insert(12, 'Source (Internal use)', \"Physicsandmathstutor\")\n",
    "\n",
    "    # Fix LaTeX delimiters in specified columns\n",
    "    columns_to_check = ['Question_Title', 'Answer', 'Mark Scheme', 'Other Text', 'Options']\n",
    "    for column in columns_to_check:\n",
    "        df[column] = df[column].apply(fix_latex_delimiters)\n",
    "\n",
    "    difficulty_values = ['easy', 'medium', 'hard']\n",
    "    \n",
    "    with pd.ExcelWriter(os.path.join(output_folder, output_file)) as writer:\n",
    "        df.to_excel(writer, index=False)\n",
    "    \n",
    "        row_num = 1  \n",
    "        last_row = len(df) + 1\n",
    "\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "        \n",
    "        # Apply data validation to the 'Difficulty' column\n",
    "        col_num = df.columns.get_loc('Difficulty')\n",
    "        worksheet.data_validation(f'${chr(col_num+65)}{row_num}:${chr(col_num+65)}{last_row}', {'validate': 'list', 'source': difficulty_values})\n",
    "\n",
    "    print(f\"[{len(df)}] Data has been successfully saved to `{output_file}`.\")\n",
    "\n",
    "# Save Json files (For testing/fixing bugs)\n",
    "def saveJSON(data,name=\"data.json\"):\n",
    "    with open(name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def read_json_file(filename='pdf_ids_logs.json'):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)  # Load the JSON data into a Python dictionary\n",
    "    return data\n",
    "\n",
    "# Function to append a new set of questions and answers pdf_ids to the JSON file\n",
    "def append_to_json_logs(pdf_ids, logs_file='pdf_ids_logs.json'):\n",
    "    # Check if the JSON file exists\n",
    "    if os.path.exists(logs_file):\n",
    "        # Read existing data\n",
    "        with open(logs_file, 'r', encoding='utf-8') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                data = []  # If the file is empty or invalid, start with an empty list\n",
    "    else:\n",
    "        data = []  # If the file does not exist, start with an empty list\n",
    "\n",
    "    # Append the new data\n",
    "    data.append(pdf_ids)\n",
    "\n",
    "    # Write the updated data back to the file\n",
    "    with open(logs_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797463e7-7690-492b-9222-4687600348d5",
   "metadata": {},
   "source": [
    "<a name=\"MP\"></a>\n",
    "## MathPix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3af613-dd45-484f-9a53-4e5fc4942abd",
   "metadata": {},
   "source": [
    "[MathPix APIs Documentation](https://docs.mathpix.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01648f69-df7b-4cb8-bac3-68467868a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MathPix\n",
    "MATHPIX_APP_ID = os.environ.get(\"MATHPIX_APP_ID\")\n",
    "MATHPIX_APP_KEY = os.environ.get(\"MATHPIX_APP_KEY\")\n",
    "\n",
    "def process_pdf(url, app_id=MATHPIX_APP_ID, app_key=MATHPIX_APP_KEY):\n",
    "    response = requests.post(\n",
    "        \"https://api.mathpix.com/v3/pdf\",\n",
    "        json={\n",
    "            \"url\": url,\n",
    "            \"conversion_formats\": {\n",
    "                \"md\": True,\n",
    "            },\n",
    "            \"math_inline_delimiters\": [\"$\", \"$\"]\n",
    "        },\n",
    "        headers={\n",
    "            \"app_id\": app_id,\n",
    "            \"app_key\": app_key,\n",
    "            \"Content-type\": \"application/json\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def process_pdfs(url_pairs):\n",
    "    pdf_ids = {\n",
    "        'questions': [],\n",
    "        'answers': []\n",
    "    }\n",
    "    print(f'Processing [{len(url_pairs)}] pairs of PDF(s)... ')\n",
    "    \n",
    "    for idx, (question_url, answer_url) in enumerate(url_pairs):\n",
    "        # Process the question PDF\n",
    "        question_url = get_pdf_embed_links(question_url)\n",
    "        print(f\"Q{idx+1}) Extracting questions from:{question_url}\", end='')\n",
    "        \n",
    "        response = process_pdf(question_url)\n",
    "        pdf_ids['questions'].append(response['pdf_id'])  # Store question PDF ID\n",
    "        \n",
    "        print(f\" | pdf_id:{response['pdf_id']}\")\n",
    "    \n",
    "        # Process the answer PDF\n",
    "        answer_url = get_pdf_embed_links(answer_url)\n",
    "        print(f\"A{idx+1}) Extracting answers from:{answer_url}\",end='')\n",
    "        \n",
    "        response = process_pdf(answer_url)\n",
    "        pdf_ids['answers'].append(response['pdf_id'])  # Store answer PDF ID\n",
    "    \n",
    "        print(f\" | pdf_id:{response['pdf_id']}\")\n",
    "\n",
    "    append_to_json_logs(pdf_ids) # Save logs for future use\n",
    "\n",
    "    return pdf_ids\n",
    "\n",
    "def get_result_in_latex(pdf_id, app_id=MATHPIX_APP_ID, app_key=MATHPIX_APP_KEY):\n",
    "    response = requests.get(\n",
    "        \"https://api.mathpix.com/v3/pdf/\" + pdf_id + \".mmd\", # get mmd response\n",
    "        headers={\n",
    "            \"app_id\": app_id,\n",
    "            \"app_key\": app_key,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "def get_results_in_latex(pdf_ids):\n",
    "    contents = {\n",
    "        'questions': [],\n",
    "        'answers': []\n",
    "    }\n",
    "    \n",
    "    # Get LaTeX contents using the stored PDF IDs\n",
    "    for idx, (ques_pdf_id, ans_pdf_id) in enumerate(zip(pdf_ids['questions'], pdf_ids['answers'])):\n",
    "        while True:\n",
    "            content = get_result_in_latex(ques_pdf_id)\n",
    "\n",
    "            if '\"status\":\"split\"' not in content:\n",
    "                contents['questions'].append(content)\n",
    "                print(f\"Q{idx+1}) Got questions contents from pdf_id:{ques_pdf_id}\")\n",
    "                break\n",
    "            else:\n",
    "                print('Wait for the file to process.. ')\n",
    "                time.sleep(2)\n",
    "\n",
    "        while True:\n",
    "            content = get_result_in_latex(ans_pdf_id)\n",
    "\n",
    "            if '\"status\":\"split\"' not in content:\n",
    "                print(f\"A{idx+1}) Got answers contents from pdf_id:{ans_pdf_id}\")\n",
    "                contents['answers'].append(content)\n",
    "                break\n",
    "            else:\n",
    "                print('Wait for the file to process.. ')\n",
    "                time.sleep(2)\n",
    "                \n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca1b1-1688-4a2d-94d6-b854b38ce7bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"OA\"></a>\n",
    "## OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b09614-0cee-4f6a-bc69-13d2a935652a",
   "metadata": {},
   "source": [
    "[OpenAI APIs Documentation](https://platform.openai.com/docs/api-reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55febb74-859f-494c-9af0-ffdd3a512ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "LLM_responses = []\n",
    "LLM_error_responses = []\n",
    "# Prompt for injecting into LLMs\n",
    "SYSTEM_PROMPT = f'''\n",
    "You will receive 2 LaTeX contents, one are the questions and one are the answers. Your task is to output a **Python list** of **JSON objects**. Each JSON object must follow this structure:\n",
    "\n",
    "- **ID**: (Required) A unique identifier for each question, generated from the question number and parent question. DO NOT FORGET the parent question that contains a general question. \n",
    "- **Difficulty**: (Required) Rate the difficulty as one of: ['easy', 'medium', 'hard'].\n",
    "- **Parent_ID**: (MUST EXIST AN ID FOR THE PARENT) For sub-questions, assign IDs based on the parent question (e.g., if the parent question is '1', sub-questions could be '1a', '1b', etc.).\n",
    "- **Question**: (Required) The full question derived from the question file. Do not summarize; ensure clarity for both parent and sub-questions.\n",
    "- **Options**: Include multiple-choice options if available; otherwise, leave as ''.\n",
    "- **Images**: Indicate if an image is associated with the question; otherwise, leave as ''.\n",
    "- **Mark Scheme**: Provide the marking scheme if available.\n",
    "- **Answer**: (Required except for questions that have sub-questions) The complete answer derived from the answer file. Do not summarize.\n",
    "- **Mark**: (Required) Must be greater than 1. If specified in the answer file, include it; otherwise, assign based on difficulty. The parent question's mark must equal the sum of its sub-questions.\n",
    "- **Other Text**: Any additional context or explanation.\n",
    "\n",
    "**IMPORTANT NOTES**:\n",
    "- Please use `$` for inline math in LaTeX.\n",
    "- Ensure your output is NOT a markdown and can be used with the `json.loads()` method to convert.\n",
    "- DO NOT put unnecessary newline, or space characters. keep the double backslash for the LaTeX format.\n",
    "- Strip empty spaces to minimize output size.\n",
    "- Do not answer questions or shorten content.\n",
    "- Ensure all sub-questions are covered and there is a parent for all sub-questions.\n",
    "- Retain any mathematical characters or equations in LaTeX format.\n",
    "- Leave fields empty ('') if information cannot be extracted.\n",
    "'''\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)  # Change model as needed\n",
    "    return len(encoding.encode(text))\n",
    "    \n",
    "def get_completion_from_messages(messages, model=\"gpt-4o-mini\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # max_tokens=6000\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_from_llm(questions_contents, answers_contents, system_message=SYSTEM_PROMPT):\n",
    "    input_contents = f\"\"\"\n",
    "    Questions File Contents: {questions_contents},\n",
    "    \n",
    "    Answers File Contents:{answers_contents}\"\"\"\n",
    "\n",
    "    messages =  [  \n",
    "    {'role':'system', 'content': system_message},    \n",
    "    # {'role':'user', 'content': f\"{few_shot_user_1}\"},  #Few-shot learning can be used here, in-case the model got hallucination issues\n",
    "    # {'role':'assistant', 'content': few_shot_assistant_1 },\n",
    "    {'role':'user', 'content': input_contents},  \n",
    "    ]\n",
    "    \n",
    "    return get_completion_from_messages(messages)\n",
    "\n",
    "def fix_llm_response(LLM_response, error, model='gpt-4o-mini'):\n",
    "    system_message = '''You will be given a string that gives an error while trying to load it into JSON format, you will be provided the error message as well\n",
    "    ONLY Output only the JSON format corrected version of the string that can be successfully loaded into JSON format.\n",
    "    '''\n",
    "\n",
    "    input_message = f'''\n",
    "    The error string is failed to load into JSON format:\n",
    "    \n",
    "    {LLM_response}\n",
    "    \n",
    "    The error message: {error}.\n",
    "    '''\n",
    "    \n",
    "    messages =  [  \n",
    "    {'role':'system', 'content': system_message},    \n",
    "    {'role':'user', 'content': input_message},  \n",
    "    ]\n",
    "\n",
    "    return get_completion_from_messages(messages)\n",
    "\n",
    "def extract_practise_exams(practise_data, contents):\n",
    "    global LLM_responses\n",
    "    for idx, (questions_contents, answers_contents) in enumerate(zip(contents['questions'], contents['answers'])):\n",
    "        pre_len = len(practise_data)\n",
    "        total_tokens = 0\n",
    "        input_tokens = count_tokens(f'{SYSTEM_PROMPT}{questions_contents}{answers_contents}')\n",
    "        total_tokens += input_tokens\n",
    "        print(f\"{idx+1}) Injecting into LLM... | Input Tokens:{input_tokens}\", end='')\n",
    "        \n",
    "        # Extract data from LLM\n",
    "        LLM_response = extract_from_llm(questions_contents, answers_contents).strip(\"```json\").strip(\"```\")\n",
    "        \n",
    "        output_tokens = count_tokens(f'{LLM_response}')\n",
    "        total_tokens += output_tokens\n",
    "        print(f' | Output Tokens:{output_tokens}',end='')\n",
    "        \n",
    "        # Handle error (if error happens while converting into JSON format)\n",
    "        cur_data = []\n",
    "        while not cur_data:\n",
    "            try:\n",
    "                cur_data = json.loads(LLM_response) # Convert string to JSON format\n",
    "            except Exception as e:\n",
    "                LLM_error_responses.append({'response':LLM_response,'error':e})\n",
    "                error_message = f'Error encountered at index `{e.pos}` character `{LLM_response[e.pos]}` in this part `...{LLM_response[e.pos-10:e.pos+10]}...`'\n",
    "                print(f'\\n{error_message} | Fixing response...', end='')\n",
    "        \n",
    "                if LLM_response[e.pos] == '\\\\' and LLM_response[e.pos + 1] != '\\\\' and LLM_response[e.pos - 1] != '\\\\': # Mostly it is missing a `\\` somewhere in the response\n",
    "                    LLM_response = f'{LLM_response[:e.pos]}{'\\\\'}{LLM_response[e.pos:]}'\n",
    "                    print(f\" [Added '\\\\']\", end='')\n",
    "                else: # Otherwise, have to use LLM to fix the response\n",
    "                    input_tokens = count_tokens(f'{LLM_response}{e} {error_message}')\n",
    "                    total_tokens += input_tokens\n",
    "                    print(f\" | Input Tokens:{input_tokens}\", end='')\n",
    "                    \n",
    "                    LLM_response = fix_llm_response(LLM_response, f'{e} {error_message}').strip(\"```json\").strip(\"```\")\n",
    "\n",
    "                    output_tokens = count_tokens(f'{LLM_response}')\n",
    "                    total_tokens += output_tokens\n",
    "                    print(f\" | Output Tokens:{output_tokens}\",end='')\n",
    "        \n",
    "        LLM_responses.append(LLM_response)\n",
    "        \n",
    "        practise_data += cur_data\n",
    "    \n",
    "        print(f\" | Total Tokens:{total_tokens} | Questions:{len(practise_data) - pre_len} | Total:{len(practise_data)}\")\n",
    "\n",
    "    return LLM_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600f0df-9899-46a0-8141-42a9f7797861",
   "metadata": {},
   "source": [
    "<a name=\"E\"></a>\n",
    "# Excution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00581c44-3350-4731-b475-95983307a464",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"RUFF\"></a>\n",
    "## Read URLS from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f950dd9-bfd4-42f8-88d8-1a6ba1986e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] Read urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('A Levels', 'Physics', 'Particles and Radiation')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_group, subject, sub_topic, urls = get_urls_from_file()\n",
    "year_group, subject, sub_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93751d-a126-448b-b3d6-0331e890c076",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"CPIL\"></a>\n",
    "## Convert PDFs into LaTeX (MathPix APIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b337c815-68f1-47fd-936c-ddc2a3bc832a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [15] pairs of PDF(s)... \n",
      " | pdf_id:2025_01_13_e99cf271cc569080484dgphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Applications%20of%20Conservation%20Laws%20QP.pdf\n",
      " | pdf_id:2025_01_13_ae2d9f37a0e60c483cbfgysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Applications%20of%20Conservation%20Laws%20MS.pdf\n",
      "Q2) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Classification%20of%20Particles%20QP.pdf | pdf_id:2025_01_13_b024e1492a56f8da33c3g\n",
      " | pdf_id:2025_01_13_c07a222d2317a8c2c14bgysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Classification%20of%20Particles%20MS.pdf\n",
      " | pdf_id:2025_01_13_566ac15ee45ee29885c6gphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Collisions%20of%20Electrons%20with%20Atoms%20QP.pdf\n",
      "A3) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Collisions%20of%20Electrons%20with%20Atoms%20MS.pdf | pdf_id:2025_01_13_a668ed00459a4ff1a3a6g\n",
      " | pdf_id:2025_01_13_fdd42c5bc6fc204dc167gphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Constituents%20of%20the%20Atom%20QP.pdf\n",
      "A4) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Constituents%20of%20the%20Atom%20MS.pdf | pdf_id:2025_01_13_2d1d03e1cad68424d44cg\n",
      " | pdf_id:2025_01_13_64606b258cbf4c5797a9gphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/EM%20Radiation%20&%20Quantum%20Phenomena%20(Multiple%20Choice)%20QP.pdf\n",
      "A5) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/EM%20Radiation%20&%20Quantum%20Phenomena%20(Multiple%20Choice)%20MS.pdf | pdf_id:2025_01_13_511c4e911b1114bcffacg\n",
      " | pdf_id:2025_01_13_b388b444e2cf9b2ed562gphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Energy%20Levels%20&%20Photon%20Emission%20QP.pdf\n",
      "A6) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Particle%20Interaction%20MS.pdf | pdf_id:2025_01_13_d8bb204b5b88264d3a4ag\n",
      " | pdf_id:2025_01_13_ae69c670b25cfaf44142gphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Particles%20(Multiple%20Choice)%20QP.pdf\n",
      "A7) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Particles%20(Multiple%20Choice)%20MS.pdf | pdf_id:2025_01_13_645c491b4d14f6361b72g\n",
      " | pdf_id:2025_01_13_a006c341d5230a1cda71gphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Particles,%20Antiparticles%20&%20Photons%20QP.pdf\n",
      "A8) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Particles,%20Antiparticles%20&%20Photons%20MS.pdf | pdf_id:2025_01_13_4d9d9dae60f965681ddag\n",
      " | pdf_id:2025_01_13_46a53be1d0ef24e55ecbgphysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Photoelectric%20Effect%20QP.pdf\n",
      "A9) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Photoelectric%20Effect%20MS.pdf | pdf_id:2025_01_13_70f8fd5c29925e1f06b4g\n",
      " | pdf_id:2025_01_13_10e8a0bc37808c8e8f0fg.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Quarks%20&%20Antiquarks%20QP.pdf\n",
      " | pdf_id:2025_01_13_1071cd84d3811484a306ghysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Quarks%20&%20Antiquarks%20MS.pdf\n",
      "Q11) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Stable%20&%20Unstable%20Nuclei%20QP.pdf | pdf_id:2025_01_13_4fa79d90bef11fdbbd04g\n",
      " | pdf_id:2025_01_13_ae537636f79e26118bf9ghysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Stable%20&%20Unstable%20Nuclei%20MS.pdf\n",
      "Q12) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Wave-Particle%20Duality%20QP.pdf | pdf_id:2025_01_13_012c631b36640952edd3g\n",
      " | pdf_id:2025_01_13_2c9795f77f52ca38d299ghysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-M/Wave-Particle%20Duality%20MS.pdf\n",
      "Q13) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-A/Nuclear%20Physics.pdf | pdf_id:2025_01_13_7eff54b1c64a1ed2e259g\n",
      " | pdf_id:2025_01_13_2c88c753d90f57b8b318ghysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-A/Nuclear%20Physics%20MS.pdf\n",
      "Q14) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-A/Particle%20Physics.pdf | pdf_id:2025_01_13_528c5cb0e34c40cd37bbg\n",
      " | pdf_id:2025_01_13_2f35ab444b04607e510bghysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-A/Particle%20Physics%20MS.pdf\n",
      "Q15) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-A/Quantum%20Physics.pdf | pdf_id:2025_01_13_ad59c2bd3dfd7d7e2920g\n",
      " | pdf_id:2025_01_13_66fb4d01277c86c24894ghysicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/02-Particles-and-Radiation/Set-A/Quantum%20Physics%20MS.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_ids = process_pdfs(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da36e6-3bc2-4062-863d-713d6876b093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"GLCUP\"></a>\n",
    "## Get LaTeX contents using `pdf_ids` (MathPix APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab807c-2bcf-41f0-94f7-c7be254ae4ec",
   "metadata": {},
   "source": [
    "Some PDFs have many pages require longer time to process (indicate as `Wait for the file to process.. `)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67fef20c-182e-4c8d-bd16-e54e77dcab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1) Got questions contents from pdf_id:2025_01_13_e99cf271cc569080484dg\n",
      "A1) Got answers contents from pdf_id:2025_01_13_ae2d9f37a0e60c483cbfg\n",
      "Q2) Got questions contents from pdf_id:2025_01_13_b024e1492a56f8da33c3g\n",
      "A2) Got answers contents from pdf_id:2025_01_13_c07a222d2317a8c2c14bg\n",
      "Q3) Got questions contents from pdf_id:2025_01_13_566ac15ee45ee29885c6g\n",
      "A3) Got answers contents from pdf_id:2025_01_13_a668ed00459a4ff1a3a6g\n",
      "Q4) Got questions contents from pdf_id:2025_01_13_fdd42c5bc6fc204dc167g\n",
      "A4) Got answers contents from pdf_id:2025_01_13_2d1d03e1cad68424d44cg\n",
      "Q5) Got questions contents from pdf_id:2025_01_13_64606b258cbf4c5797a9g\n",
      "A5) Got answers contents from pdf_id:2025_01_13_511c4e911b1114bcffacg\n",
      "Q6) Got questions contents from pdf_id:2025_01_13_b388b444e2cf9b2ed562g\n",
      "A6) Got answers contents from pdf_id:2025_01_13_d8bb204b5b88264d3a4ag\n",
      "Q7) Got questions contents from pdf_id:2025_01_13_ae69c670b25cfaf44142g\n",
      "A7) Got answers contents from pdf_id:2025_01_13_645c491b4d14f6361b72g\n",
      "Q8) Got questions contents from pdf_id:2025_01_13_a006c341d5230a1cda71g\n",
      "A8) Got answers contents from pdf_id:2025_01_13_4d9d9dae60f965681ddag\n",
      "Q9) Got questions contents from pdf_id:2025_01_13_46a53be1d0ef24e55ecbg\n",
      "Wait for the file to process.. \n",
      "A9) Got answers contents from pdf_id:2025_01_13_70f8fd5c29925e1f06b4g\n",
      "Q10) Got questions contents from pdf_id:2025_01_13_10e8a0bc37808c8e8f0fg\n",
      "A10) Got answers contents from pdf_id:2025_01_13_1071cd84d3811484a306g\n",
      "Q11) Got questions contents from pdf_id:2025_01_13_4fa79d90bef11fdbbd04g\n",
      "A11) Got answers contents from pdf_id:2025_01_13_ae537636f79e26118bf9g\n",
      "Q12) Got questions contents from pdf_id:2025_01_13_012c631b36640952edd3g\n",
      "A12) Got answers contents from pdf_id:2025_01_13_2c9795f77f52ca38d299g\n",
      "Q13) Got questions contents from pdf_id:2025_01_13_7eff54b1c64a1ed2e259g\n",
      "A13) Got answers contents from pdf_id:2025_01_13_2c88c753d90f57b8b318g\n",
      "Q14) Got questions contents from pdf_id:2025_01_13_528c5cb0e34c40cd37bbg\n",
      "A14) Got answers contents from pdf_id:2025_01_13_2f35ab444b04607e510bg\n",
      "Q15) Got questions contents from pdf_id:2025_01_13_ad59c2bd3dfd7d7e2920g\n",
      "A15) Got answers contents from pdf_id:2025_01_13_66fb4d01277c86c24894g\n"
     ]
    }
   ],
   "source": [
    "pdf_ids = read_json_file()[-1]\n",
    "contents = get_results_in_latex(pdf_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fe3f5-636a-4fc0-bb83-54102c691261",
   "metadata": {},
   "source": [
    "<a name=\"IJIL\"></a>\n",
    "## Injecting into LLM (OpenAI APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf3440-0cb1-4590-af92-f92fd46a1f2c",
   "metadata": {},
   "source": [
    "- Currently using [gpt-4o-mini](https://platform.openai.com/docs/models/gpt-4o-mini) the most cost-efficient small model thatâ€™s smarter and cheaper than GPT-3.5 Turbo, and has vision capabilities. (Max output tokens: **16,384** tokens)\n",
    "- Other GPT with higher output tokens can be used (in case there are lots of questions in 1 PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e81948-04a6-4946-a59b-4c76d5f65028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Injecting into LLM... | Input Tokens:2600 | Output Tokens:2292\n",
      "Error encountered at index `136` character `\\` in this part `...ve pion, $\\pi^{+}$, ...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `5369` character `\\` in this part `... \\\\pi^{-}+\\mathrm{p}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `6676` character `\\` in this part `... \\\\pi^{+}+\\mathrm{n}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `6701` character `\\` in this part `...ightarrow \\mathrm{p}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `6713` character `\\` in this part `...mathrm{p}+\\pi \\\\] (i...` | Fixing response... [Added '\\'] | Total Tokens:4892 | Questions:29 | Total:29\n",
      " | Output Tokens:2806... | Input Tokens:4055\n",
      "Error encountered at index `2784` character `\\` in this part `... quark ( $\\mathrm{u}...` | Fixing response... [Added '\\'] | Total Tokens:6861 | Questions:24 | Total:53\n",
      " | Output Tokens:2204 | Total Tokens:5353 | Questions:29 | Total:82\n",
      " | Output Tokens:3068 | Total Tokens:6999 | Questions:19 | Total:101\n",
      " | Output Tokens:3065 | Total Tokens:6700 | Questions:20 | Total:121\n",
      " | Output Tokens:1466 | Total Tokens:4771 | Questions:20 | Total:141\n",
      " | Output Tokens:4721... | Input Tokens:4764\n",
      "Error encountered at index `8307` character `\\` in this part `...wo slits $\\mathrm{S}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8329` character `\\` in this part `...{1}$ and $\\mathrm{S}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8513` character `\\` in this part `...ant from $\\mathrm{S}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8535` character `\\` in this part `...{1}$ and $\\mathrm{S}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `9493` character `\\` in this part `...laced at $\\mathrm{S}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `9515` character `\\` in this part `...{1}$ and $\\mathrm{S}...` | Fixing response... [Added '\\'] | Total Tokens:9485 | Questions:48 | Total:189\n",
      " | Output Tokens:3153 | Total Tokens:6267 | Questions:28 | Total:217\n",
      " | Output Tokens:2017 | Total Tokens:6408 | Questions:21 | Total:238\n",
      " | Output Tokens:2974M... | Input Tokens:3123\n",
      "Error encountered at index `932` character `\\` in this part `... quark ( $\\mathrm{u}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `955` character `\\` in this part `...\\overline{\\mathrm{s}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1085` character `\\` in this part `...ons of ( $\\mathrm{u}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1108` character `\\` in this part `...\\overline{\\mathrm{d}...` | Fixing response... [Added '\\'] | Total Tokens:6097 | Questions:32 | Total:270\n",
      " | Output Tokens:2170M... | Input Tokens:4072\n",
      "Error encountered at index `2366` character `\\` in this part `...lain why $\\gamma$ ra...` | Fixing response... [Added '\\'] | Total Tokens:6242 | Questions:30 | Total:300\n",
      " | Output Tokens:2884 | Total Tokens:7139 | Questions:24 | Total:324\n",
      " | Output Tokens:5447M... | Input Tokens:5481\n",
      "Error encountered at index `914` character `\\` in this part `...92}^{238} \\cup$ nucl...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `19137` character `\\` in this part `...\":\"$\\\\bar{\\gamma} \\\\...` | Fixing response... [Added '\\'] | Total Tokens:10928 | Questions:57 | Total:381\n",
      " | Output Tokens:2159M... | Input Tokens:5412\n",
      "Error encountered at index `70` character `\\` in this part `...\"(a) The $\\mathrm{K}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `546` character `\\` in this part `...r of the $\\mathrm{K}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `755` character `\\` in this part `...n of the $\\mathrm{K}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1543` character `\\` in this part `...when the $\\mathrm{W}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1928` character `\\` in this part `...cay of a $\\mathrm{K}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `4041` character `\\` in this part `...r than a $\\mathrm{W}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `4061` character `\\` in this part `...}^{+}$or $\\mathrm{W}...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `7617` character `\\` in this part `...article: $\\overline{...` | Fixing response... [Added '\\'] | Total Tokens:7571 | Questions:35 | Total:416\n",
      " | Output Tokens:6584M... | Input Tokens:8793\n",
      "Error encountered at index `7402` character `\\` in this part `...thbf{1}$ $\\left(v=1....` | Fixing response... [Added '\\']\n",
      "Error encountered at index `13265` character `\\` in this part `...$E=h f$) $\\Delta E=3...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `13740` character `\\` in this part `...{c}{f}$) $\\lambda=\\\\...` | Fixing response... [Added '\\'] | Total Tokens:15377 | Questions:58 | Total:474\n"
     ]
    }
   ],
   "source": [
    "practise_data = []\n",
    "LLM_responses = []\n",
    "LLM_responses = extract_practise_exams(practise_data, contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e8b2821-5d28-42b0-94be-574528a34720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[474] Data has been successfully saved to `particles and radiation a levels physics.xlsx`.\n"
     ]
    }
   ],
   "source": [
    "output_file = f\"{sub_topic.lower()} {year_group.lower()} {subject.lower()}.xlsx\"\n",
    "save_excel(output_file, practise_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".practise_exam_scraper_env",
   "language": "python",
   "name": ".practise_exam_scraper_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
