{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132c6fa0-694c-409b-8aed-6b0da3451e11",
   "metadata": {},
   "source": [
    "# Outline\n",
    " \n",
    "- [ Required Packages](#RP)\n",
    "- [ Define Functions](#DF)\n",
    "  - [ Utility Functions](#UF)\n",
    "  - [ MathPix](#MP)\n",
    "  - [ OpenAI](#OA)\n",
    "- [ Execution ](#E)\n",
    "    - [ Read URLS from file ](#RUFF)\n",
    "    - [ Convert PDFs into LaTeX (MathPix APIs) ](#CPIL)\n",
    "    - [ Get LaTeX contents using `pdf_ids` (MathPix APIs) ](#GLCUP)\n",
    "    - [ Injecting into LLM (OpenAI APIs) ](#IJIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33981e84",
   "metadata": {
    "height": 30,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"RP\"></a>\n",
    "# Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91f0a724",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# pip install pandas requests openpyxl xlsxwriter tiktoken openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1124b54e",
   "metadata": {
    "height": 218
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import xlsxwriter\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a6f7cd-d2b9-4104-be03-75be0893df2b",
   "metadata": {},
   "source": [
    "<a name=\"DF\"></a>\n",
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e16cc2-e4a8-43f8-acd4-19cc80de39ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"UF\"></a>\n",
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7dea77c0-71ad-4e01-bd2f-602366e0f6e9",
   "metadata": {
    "height": 1282
   },
   "outputs": [],
   "source": [
    "def get_pdf_embed_links(url):\n",
    "    if \"https://pmt\" not in url:\n",
    "        # Extract the 'pdf' parameter from the query string\n",
    "        parsed_url = urllib.parse.urlparse(url)\n",
    "        pdf_url = urllib.parse.parse_qs(parsed_url.query)['pdf'][0]\n",
    "        \n",
    "        # Decode the URL\n",
    "        decoded_url = urllib.parse.unquote(pdf_url).replace(' ', '%20')\n",
    "        return decoded_url\n",
    "    else:\n",
    "        return url.replace(' ', '%20')\n",
    "\n",
    "def get_urls_from_file(filename = 'input_urls.txt'):\n",
    "    urls = []\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    year_group = lines[0].strip()\n",
    "    subject = lines[1].strip()\n",
    "    sub_topic = lines[2].strip()\n",
    "    \n",
    "    url_group = []\n",
    "    for line in lines[3:]:\n",
    "        url_group = line.strip().split(' https://')\n",
    "        url_group[0] = get_pdf_embed_links(url_group[0])\n",
    "        url_group[1] = get_pdf_embed_links(f'{'https://'}{url_group[1]}')\n",
    "    \n",
    "        if len(url_group) == 2:\n",
    "            urls.append(tuple(url_group))\n",
    "        else:\n",
    "            print(f'Missing 1 pair: {url_group}')\n",
    "\n",
    "    if len(lines) == len(urls)+3:\n",
    "        print(f\"[{len(urls)}] Read urls\")\n",
    "    else:\n",
    "        print(f\"[{len(urls)}] Failed to read urls\")\n",
    "    \n",
    "    return year_group, subject, sub_topic, urls\n",
    "\n",
    "def fix_latex_delimiters(latex_string):\n",
    "    if not isinstance(latex_string, str):\n",
    "        return latex_string\n",
    "        \n",
    "    # Count the number of double dollar signs\n",
    "    double_dollar_count = latex_string.count('$$')\n",
    "    \n",
    "    # Check if the count of double dollar signs is odd\n",
    "    if double_dollar_count % 2 != 0:\n",
    "        latex_string += ' $$'\n",
    "        \n",
    "    # Count the number of single dollar signs\n",
    "    single_dollar_count = latex_string.count('$')\n",
    "    \n",
    "    # Check if the count of single dollar signs is odd\n",
    "    if single_dollar_count % 2 != 0:\n",
    "        latex_string += ' $'\n",
    "    \n",
    "    return latex_string\n",
    "\n",
    "# Save to excel file with Data Validation\n",
    "def save_excel(practise_data, output_file=\"file.xlsx\"):\n",
    "    df = pd.DataFrame(practise_data).rename(columns={'Question':'Question_Title'})\n",
    "    df.insert(1, 'Year Group', year_group)\n",
    "    df.insert(2, 'Subject', subject)\n",
    "    df.insert(3, 'Sub-Topic', sub_topic)\n",
    "    df.insert(6, 'Type of question', \"Practise Exam\")\n",
    "    df.insert(12, 'Source (Internal use)', \"Physicsandmathstutor\")\n",
    "\n",
    "    # Fix LaTeX delimiters in specified columns\n",
    "    columns_to_check = ['Question_Title', 'Answer', 'Mark Scheme', 'Other Text', 'Options']\n",
    "    for column in columns_to_check:\n",
    "        df[column] = df[column].apply(fix_latex_delimiters)\n",
    "\n",
    "    difficulty_values = ['easy', 'medium', 'hard']\n",
    "    \n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        df.to_excel(writer, index=False)\n",
    "    \n",
    "        row_num = 1  \n",
    "        last_row = len(df) + 1\n",
    "\n",
    "        worksheet = writer.sheets['Sheet1']\n",
    "        \n",
    "        # Apply data validation to the 'Difficulty' column\n",
    "        col_num = df.columns.get_loc('Difficulty')\n",
    "        worksheet.data_validation(f'${chr(col_num+65)}{row_num}:${chr(col_num+65)}{last_row}', {'validate': 'list', 'source': difficulty_values})\n",
    "\n",
    "    print(f\"[{len(df)}] Quiz data has been successfully saved to `{output_file}`.\")\n",
    "\n",
    "# Save Json files (For testing/fixing bugs)\n",
    "def saveJSON(data,name=\"data.json\"):\n",
    "    with open(name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def read_json_file(filename='pdf_ids_logs.json'):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)  # Load the JSON data into a Python dictionary\n",
    "    return data\n",
    "\n",
    "# Function to append a new set of questions and answers pdf_ids to the JSON file\n",
    "def append_to_json_logs(pdf_ids, logs_file='pdf_ids_logs.json'):\n",
    "    # Check if the JSON file exists\n",
    "    if os.path.exists(logs_file):\n",
    "        # Read existing data\n",
    "        with open(logs_file, 'r', encoding='utf-8') as file:\n",
    "            try:\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                data = []  # If the file is empty or invalid, start with an empty list\n",
    "    else:\n",
    "        data = []  # If the file does not exist, start with an empty list\n",
    "\n",
    "    # Append the new data\n",
    "    data.append(pdf_ids)\n",
    "\n",
    "    # Write the updated data back to the file\n",
    "    with open(logs_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797463e7-7690-492b-9222-4687600348d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"MP\"></a>\n",
    "## MathPix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01648f69-df7b-4cb8-bac3-68467868a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MathPix\n",
    "MATHPIX_APP_ID = os.environ.get(\"MATHPIX_APP_ID\")\n",
    "MATHPIX_APP_KEY = os.environ.get(\"MATHPIX_APP_KEY\")\n",
    "\n",
    "def process_pdf(url, app_id=MATHPIX_APP_ID, app_key=MATHPIX_APP_KEY):\n",
    "    response = requests.post(\n",
    "        \"https://api.mathpix.com/v3/pdf\",\n",
    "        json={\n",
    "            \"url\": url,\n",
    "            \"conversion_formats\": {\n",
    "                \"md\": True,\n",
    "            },\n",
    "            \"math_inline_delimiters\": [\"$\", \"$\"]\n",
    "        },\n",
    "        headers={\n",
    "            \"app_id\": app_id,\n",
    "            \"app_key\": app_key,\n",
    "            \"Content-type\": \"application/json\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "def process_pdfs(url_pairs):\n",
    "    pdf_ids = {\n",
    "        'questions': [],\n",
    "        'answers': []\n",
    "    }\n",
    "    print(f'Processing [{len(url_pairs)}] pairs of PDF(s)... ')\n",
    "    \n",
    "    for idx, (question_url, answer_url) in enumerate(url_pairs):\n",
    "        # Process the question PDF\n",
    "        question_url = get_pdf_embed_links(question_url)\n",
    "        print(f\"Q{idx+1}) Extracting questions from:{question_url}\", end='')\n",
    "        \n",
    "        response = process_pdf(question_url)\n",
    "        pdf_ids['questions'].append(response['pdf_id'])  # Store question PDF ID\n",
    "        \n",
    "        print(f\" | pdf_id:{response['pdf_id']}\")\n",
    "    \n",
    "        # Process the answer PDF\n",
    "        answer_url = get_pdf_embed_links(answer_url)\n",
    "        print(f\"A{idx+1}) Extracting answers from:{answer_url}\",end='')\n",
    "        \n",
    "        response = process_pdf(answer_url)\n",
    "        pdf_ids['answers'].append(response['pdf_id'])  # Store answer PDF ID\n",
    "    \n",
    "        print(f\" | pdf_id:{response['pdf_id']}\")\n",
    "\n",
    "    append_to_json_logs(pdf_ids) # Save logs for future use\n",
    "\n",
    "    return pdf_ids\n",
    "\n",
    "def get_result_in_latex(pdf_id, app_id=MATHPIX_APP_ID, app_key=MATHPIX_APP_KEY):\n",
    "    response = requests.get(\n",
    "        \"https://api.mathpix.com/v3/pdf/\" + pdf_id + \".mmd\", # get mmd response\n",
    "        headers={\n",
    "            \"app_id\": app_id,\n",
    "            \"app_key\": app_key,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "def get_results_in_latex(pdf_ids):\n",
    "    contents = {\n",
    "        'questions': [],\n",
    "        'answers': []\n",
    "    }\n",
    "    \n",
    "    # Get LaTeX contents using the stored PDF IDs\n",
    "    for idx, (ques_pdf_id, ans_pdf_id) in enumerate(zip(pdf_ids['questions'], pdf_ids['answers'])):\n",
    "        while True:\n",
    "            content = get_result_in_latex(ques_pdf_id)\n",
    "\n",
    "            if '\"status\":\"split\"' not in content:\n",
    "                contents['questions'].append(content)\n",
    "                print(f\"Q{idx+1}) Got questions contents from pdf_id:{ques_pdf_id}\")\n",
    "                break\n",
    "            else:\n",
    "                print('Wait for the file to process.. ')\n",
    "                time.sleep(2)\n",
    "\n",
    "        while True:\n",
    "            content = get_result_in_latex(ans_pdf_id)\n",
    "\n",
    "            if '\"status\":\"split\"' not in content:\n",
    "                print(f\"A{idx+1}) Got answers contents from pdf_id:{ans_pdf_id}\")\n",
    "                contents['answers'].append(content)\n",
    "                break\n",
    "            else:\n",
    "                print('Wait for the file to process.. ')\n",
    "                time.sleep(2)\n",
    "                \n",
    "    return contents\n",
    "\n",
    "# def pdfs_to_latex(urls):\n",
    "#     pdf_ids = process_pdfs(urls)\n",
    "\n",
    "#     print(f'Processing [{len(urls)}] pairs of PDF(s)... ')\n",
    "#     contents = get_results_in_latex(pdf_ids)\n",
    "#     return pdf_ids, contents "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4ca1b1-1688-4a2d-94d6-b854b38ce7bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a name=\"OA\"></a>\n",
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "55febb74-859f-494c-9af0-ffdd3a512ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "LLM_responses = []\n",
    "LLM_error_responses = []\n",
    "# Prompt for injecting into LLMs\n",
    "SYSTEM_PROMPT = f'''\n",
    "You will receive 2 LaTeX contents, one are the questions and one are the answers. Your task is to output a **Python list** of **JSON objects**. Each JSON object must follow this structure:\n",
    "\n",
    "- **ID**: (Required) A unique identifier for each question, generated from the question number and parent question. DO NOT FORGET the parent question that contains a general question. \n",
    "- **Difficulty**: (Required) Rate the difficulty as one of: ['easy', 'medium', 'hard'].\n",
    "- **Parent_ID**: (MUST EXIST AN ID FOR THE PARENT) For sub-questions, assign IDs based on the parent question (e.g., if the parent question is '1', sub-questions could be '1a', '1b', etc.).\n",
    "- **Question**: (Required) The full question derived from the question file. Do not summarize; ensure clarity for both parent and sub-questions.\n",
    "- **Options**: Include multiple-choice options if available; otherwise, leave as ''.\n",
    "- **Images**: Indicate if an image is associated with the question; otherwise, leave as ''.\n",
    "- **Mark Scheme**: Provide the marking scheme if available.\n",
    "- **Answer**: (Required except for questions that have sub-questions) The complete answer derived from the answer file. Do not summarize.\n",
    "- **Mark**: (Required) Must be greater than 1. If specified in the answer file, include it; otherwise, assign based on difficulty. The parent question's mark must equal the sum of its sub-questions.\n",
    "- **Other Text**: Any additional context or explanation.\n",
    "\n",
    "**IMPORTANT NOTES**:\n",
    "- Please use `$` for inline math in LaTeX.\n",
    "- Ensure your output is NOT a markdown and can be used with the `json.loads()` method to convert.\n",
    "- DO NOT put unnecessary newline, or space characters. keep the double backslash for the LaTeX format.\n",
    "- Strip empty spaces to minimize output size.\n",
    "- Do not answer questions or shorten content.\n",
    "- Ensure all sub-questions are covered and there is a parent for all sub-questions.\n",
    "- Retain any mathematical characters or equations in LaTeX format.\n",
    "- Leave fields empty ('') if information cannot be extracted.\n",
    "'''\n",
    "\n",
    "def count_tokens(text, model=\"gpt-4o-mini\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)  # Change model as needed\n",
    "    return len(encoding.encode(text))\n",
    "    \n",
    "def get_completion_from_messages(messages, model=\"gpt-4o-mini\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        # max_tokens=6000\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_from_llm(questions_contents, answers_contents, system_message=SYSTEM_PROMPT):\n",
    "    input_contents = f\"\"\"\n",
    "    Questions File Contents: {questions_contents},\n",
    "    \n",
    "    Answers File Contents:{answers_contents}\"\"\"\n",
    "\n",
    "    messages =  [  \n",
    "    {'role':'system', 'content': system_message},    \n",
    "    # {'role':'user', 'content': f\"{few_shot_user_1}\"},  #Few-shot learning can be used here, in-case the model got hallucination issues\n",
    "    # {'role':'assistant', 'content': few_shot_assistant_1 },\n",
    "    {'role':'user', 'content': input_contents},  \n",
    "    ]\n",
    "    \n",
    "    return get_completion_from_messages(messages)\n",
    "\n",
    "def fix_llm_response(LLM_response, error, model='gpt-4o-mini'):\n",
    "    system_message = '''You will be given a string that gives an error while trying to load it into JSON format, you will be provided the error message as well\n",
    "    ONLY Output only the JSON format corrected version of the string that can be successfully loaded into JSON format.\n",
    "    '''\n",
    "\n",
    "    input_message = f'''\n",
    "    The error string is failed to load into JSON format:\n",
    "    \n",
    "    {LLM_response}\n",
    "    \n",
    "    The error message: {error}.\n",
    "    '''\n",
    "    \n",
    "    messages =  [  \n",
    "    {'role':'system', 'content': system_message},    \n",
    "    {'role':'user', 'content': input_message},  \n",
    "    ]\n",
    "\n",
    "    return get_completion_from_messages(messages)\n",
    "\n",
    "def extract_practise_exams(practise_data, contents):\n",
    "    global LLM_responses\n",
    "    for idx, (questions_contents, answers_contents) in enumerate(zip(contents['questions'], contents['answers'])):\n",
    "        pre_len = len(practise_data)\n",
    "        total_tokens = 0\n",
    "        input_tokens = count_tokens(f'{SYSTEM_PROMPT}{questions_contents}{answers_contents}')\n",
    "        total_tokens += input_tokens\n",
    "        print(f\"{idx+1}) Injecting into LLM... | Input Tokens:{input_tokens}\", end='')\n",
    "        \n",
    "        # Extract data from LLM\n",
    "        LLM_response = extract_from_llm(questions_contents, answers_contents).strip(\"```json\").strip(\"```\")\n",
    "        \n",
    "        output_tokens = count_tokens(f'{LLM_response}')\n",
    "        total_tokens += output_tokens\n",
    "        print(f' | Output Tokens:{output_tokens}',end='')\n",
    "        \n",
    "        # Handle error (if error happens while converting into JSON format)\n",
    "        cur_data = []\n",
    "        while not cur_data:\n",
    "            try:\n",
    "                cur_data = json.loads(LLM_response) # Convert string to JSON format\n",
    "            except Exception as e:\n",
    "                LLM_error_responses.append({'response':LLM_response,'error':e})\n",
    "                error_message = f'Error encountered at index `{e.pos}` character `{LLM_response[e.pos]}` in this part `...{LLM_response[e.pos-10:e.pos+10]}...`'\n",
    "                print(f'\\n{error_message} | Fixing response...', end='')\n",
    "        \n",
    "                if LLM_response[e.pos] == '\\\\' and LLM_response[e.pos + 1] != '\\\\' and LLM_response[e.pos - 1] != '\\\\': # Mostly it is missing a `\\` somewhere in the response\n",
    "                    LLM_response = f'{LLM_response[:e.pos]}{'\\\\'}{LLM_response[e.pos:]}'\n",
    "                    print(f\" [Added '\\\\']\", end='')\n",
    "                else: # Otherwise, have to use LLM to fix the response\n",
    "                    input_tokens = count_tokens(f'{LLM_response}{e} {error_message}')\n",
    "                    total_tokens += input_tokens\n",
    "                    print(f\" | Input Tokens:{input_tokens}\", end='')\n",
    "                    \n",
    "                    LLM_response = fix_llm_response(LLM_response, f'{e} {error_message}').strip(\"```json\").strip(\"```\")\n",
    "\n",
    "                    output_tokens = count_tokens(f'{LLM_response}')\n",
    "                    total_tokens += output_tokens\n",
    "                    print(f\" | Output Tokens:{output_tokens}\",end='')\n",
    "        \n",
    "        LLM_responses.append(LLM_response)\n",
    "        \n",
    "        practise_data += cur_data\n",
    "    \n",
    "        print(f\" | Total Tokens:{total_tokens} | Questions:{len(practise_data) - pre_len} | Total:{len(practise_data)}\")\n",
    "\n",
    "    return LLM_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600f0df-9899-46a0-8141-42a9f7797861",
   "metadata": {},
   "source": [
    "<a name=\"E\"></a>\n",
    "# Excution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00581c44-3350-4731-b475-95983307a464",
   "metadata": {},
   "source": [
    "<a name=\"RUFF\"></a>\n",
    "## Read URLS from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f950dd9-bfd4-42f8-88d8-1a6ba1986e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Read urls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('A Levels', 'Physics', 'Measurements and Their Errors')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_group, subject, sub_topic, urls = get_urls_from_file()\n",
    "year_group, subject, sub_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93751d-a126-448b-b3d6-0331e890c076",
   "metadata": {},
   "source": [
    "<a name=\"CPIL\"></a>\n",
    "## Convert PDFs into LaTeX (MathPix APIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b337c815-68f1-47fd-936c-ddc2a3bc832a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [4] pairs of PDF(s)... \n",
      "Q1) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Estimation%20of%20Physical%20Quantities%20QP.pdf | pdf_id:2024_09_27_b9a05dccf207e83235dbg\n",
      "A1) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Estimation%20of%20Physical%20Quantities%20MS.pdf | pdf_id:2024_09_27_6afdc1b4a0429918f841g\n",
      "Q2) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Limitation%20of%20Physical%20Measurements%20QP.pdf | pdf_id:2024_09_27_1542617877fb9eee420fg\n",
      "A2) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Limitation%20of%20Physical%20Measurements%20MS.pdf | pdf_id:2024_09_27_54c65d8af204a61dc356g\n",
      "Q3) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Use%20of%20SI%20Units%20&%20Prefixes%20(Multiple%20Choice)%20QP.pdf | pdf_id:2024_09_27_2f0e2cb109aa4b80fe59g\n",
      "A3) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Use%20of%20SI%20Units%20&%20Prefixes%20(Multiple%20Choice)%20MS.pdf | pdf_id:2024_09_27_723e590f6fbe9424ac8cg\n",
      "Q4) Extracting questions from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Use%20of%20SI%20Units%20&%20Prefixes%20QP.pdf | pdf_id:2024_09_27_94450d060a4146363cfcg\n",
      "A4) Extracting answers from:https://pmt.physicsandmathstutor.com/download/Physics/A-level/Topic-Qs/AQA/01-Measurements-and-Errors/Set-M/Use%20of%20SI%20Units%20&%20Prefixes%20MS.pdf | pdf_id:2024_09_27_c066c9550dc78b454450g\n"
     ]
    }
   ],
   "source": [
    "pdf_ids = process_pdfs(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da36e6-3bc2-4062-863d-713d6876b093",
   "metadata": {},
   "source": [
    "<a name=\"GLCUP\"></a>\n",
    "## Get LaTeX contents using `pdf_ids` (MathPix APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab807c-2bcf-41f0-94f7-c7be254ae4ec",
   "metadata": {},
   "source": [
    "Some PDFs have many pages require longer time to process (indicate as `Wait for the file to process.. `)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67fef20c-182e-4c8d-bd16-e54e77dcab1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait for the file to process.. \n",
      "Q1) Got questions contents from pdf_id:2024_09_27_b9a05dccf207e83235dbg\n",
      "A1) Got answers contents from pdf_id:2024_09_27_6afdc1b4a0429918f841g\n",
      "Q2) Got questions contents from pdf_id:2024_09_27_1542617877fb9eee420fg\n",
      "A2) Got answers contents from pdf_id:2024_09_27_54c65d8af204a61dc356g\n",
      "Q3) Got questions contents from pdf_id:2024_09_27_2f0e2cb109aa4b80fe59g\n",
      "A3) Got answers contents from pdf_id:2024_09_27_723e590f6fbe9424ac8cg\n",
      "Q4) Got questions contents from pdf_id:2024_09_27_94450d060a4146363cfcg\n",
      "A4) Got answers contents from pdf_id:2024_09_27_c066c9550dc78b454450g\n"
     ]
    }
   ],
   "source": [
    "pdf_ids = read_json_file()[-1]\n",
    "contents = get_results_in_latex(pdf_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fe3f5-636a-4fc0-bb83-54102c691261",
   "metadata": {},
   "source": [
    "<a name=\"IJIL\"></a>\n",
    "## Injecting into LLM (OpenAI APIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cf3440-0cb1-4590-af92-f92fd46a1f2c",
   "metadata": {},
   "source": [
    "- Currently using [gpt-4o-mini](https://platform.openai.com/docs/models/gpt-4o-mini) the most cost-efficient small model that’s smarter and cheaper than GPT-3.5 Turbo, and has vision capabilities. (Max output tokens: **16,384** tokens)\n",
    "- Other GPT with higher output tokens can be used (in case there are lots of questions in 1 PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51e81948-04a6-4946-a59b-4c76d5f65028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Injecting into LLM... | Input Tokens:1065 | Output Tokens:962 | Total Tokens:2027 | Questions:5 | Total:5\n",
      "2) Injecting into LLM... | Input Tokens:2970 | Output Tokens:1882 | Total Tokens:4852 | Questions:19 | Total:24\n",
      "3) Injecting into LLM... | Input Tokens:1648 | Output Tokens:1530 | Total Tokens:3178 | Questions:11 | Total:35\n",
      "4) Injecting into LLM... | Input Tokens:3828 | Output Tokens:2313\n",
      "Error encountered at index `695` character `\\` in this part `...cing $=$ $\\qquad$ mm...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `996` character `\\` in this part `...tainty = $\\qquad$ mm...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1020` character `\\` in this part `...Answer\":\"$\\pm 0.01 \\...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1439` character `\\` in this part `...pacing = $\\qquad$ mm...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `1534` character `\\` in this part `...in range $\\pm 0.05$\"...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8788` character `\\` in this part `...})$? A N $\\square$ B...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8813` character `\\` in this part `...g$^{-1}$ $\\square$ C...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8829` character `\\` in this part `...re$ C Nm $\\square$ D...` | Fixing response... [Added '\\']\n",
      "Error encountered at index `8853` character `\\` in this part `...m$^{-2}$ $\\square$\",...` | Fixing response... [Added '\\'] | Total Tokens:6141 | Questions:30 | Total:65\n"
     ]
    }
   ],
   "source": [
    "practise_data = []\n",
    "LLM_responses = []\n",
    "LLM_responses = extract_practise_exams(practise_data, contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e8b2821-5d28-42b0-94be-574528a34720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65] Quiz data has been successfully saved to `measurements and their errors a levels physics.xlsx`.\n"
     ]
    }
   ],
   "source": [
    "output_file = f\"{sub_topic.lower()} {year_group.lower()} {subject.lower()}.xlsx\"\n",
    "save_excel(practise_data, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice_exam_scraper_env",
   "language": "python",
   "name": "practice_exam_scraper_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
